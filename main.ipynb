{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ba3feca",
   "metadata": {},
   "source": [
    "### Stage 2. Data preparation.\n",
    "\n",
    "To prepare data I will use Pandas and Numpy libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "143a3ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/anafem/.local/lib/python3.8/site-packages (1.4.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/anafem/.local/lib/python3.8/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/anafem/.local/lib/python3.8/site-packages (from pandas) (1.22.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/anafem/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install pandas library\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "623489bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372cd246",
   "metadata": {},
   "source": [
    "For further analysis, we will need the next datasets: \n",
    "1. match.csv\n",
    "2. players.csv\n",
    "3. hero_names.csv\n",
    "\n",
    "Create DataFrames from these datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5091351",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'match.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m match_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmatch.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m players_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplayers.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m hero_names_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhero_names.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'match.csv'"
     ]
    }
   ],
   "source": [
    "match_df = pd.read_csv(\"match.csv\")\n",
    "players_df = pd.read_csv(\"players.csv\")\n",
    "hero_names_df = pd.read_csv(\"hero_names.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26206668",
   "metadata": {},
   "source": [
    "To analyse the data I can use only the Pandas library and its syntaxis. But one of the conditions of our task is to use not only Python, but also SQL. For this purpose I will create a serverless database using built-in sqlite3 module and subsequently will convert our prepared DataFrames to database tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b48238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "def create_connection(db_file: str) -> sqlite3.connect:\n",
    "    \"\"\" create a database connection to a SQLite database \"\"\"\n",
    "    conn = None\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except sqlite3.Error as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42185e3",
   "metadata": {},
   "source": [
    "##### match_df preparation.\n",
    "I want to examine the next indicators using only the match_df:\n",
    "- how often had won a team which had Megacreeps (in percents);\n",
    "- which percentage of games were won by destroying the only one lane (in percents);\n",
    "\n",
    "For there purposes, we need to interpret barracks_status column in the appropriate way\n",
    "\n",
    "(IMPORTANT: see docs about these columns here https://wiki.teamfortress.com/wiki/WebAPI/GetMatchDetails#Barracks%20Status)\n",
    "\n",
    "Reinforced creeps are creeps with increased amount of health and damage. A team has the reinforced creeps on a particular lane if all the defence towers and all the barracks of the enemy team on this lane were destroyed. You cannot attack tier2 tower before you destroyed tier1 tower and so on. \n",
    "\n",
    "Megacreeps are hightly reinforced creeps with huge amount of health and damage. A team has the Megacreeps if all the barracks of the enemy team were destroyed.\n",
    "\n",
    "In the code below, we will convert integers from  the \"_status_\" columns to its binary representation and\n",
    "add appropriate columns which will be show us \"Megacreeps\"  and \"naked\" Ancient status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define several service functions\n",
    "\n",
    "import typing as tp\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class Lanes(Enum):\n",
    "    top = 0\n",
    "    middle = 1\n",
    "    bottom = 2\n",
    "    \n",
    "\n",
    "def int_to_binary(number: int) -> str:\n",
    "    return format(number, \"b\")\n",
    "\n",
    "\n",
    "def get_line_barracks_status(number: int, lane: int) -> int:\n",
    "    # There are two barracks on the same line, \n",
    "    # and they are represented by pairs of bits, starting with the least significant bit\n",
    "    n = 2\n",
    "    number = number >> n * lane\n",
    "    binary_repr = int_to_binary(number=number)\n",
    "    if int(binary_repr[-n:]) == 0:\n",
    "        return 0\n",
    "    return 1\n",
    "\n",
    "def has_megacreeps(row: pd.DataFrame, enemy_team: str) -> bool:\n",
    "    return not any([row[f\"{lane.name}_lane_status_{enemy_team}\"] for lane in Lanes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14753fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can add new columns to match_df\n",
    "\n",
    "barracks_status = \"barracks_status\"\n",
    "\n",
    "for team in (\"dire\", \"radiant\"):\n",
    "    init_col = f\"{barracks_status}_{team}\"\n",
    "    for lane in Lanes:\n",
    "        result_col = f\"{lane.name}_lane_status_{team}\"\n",
    "        match_df[result_col] = match_df[init_col].apply(\n",
    "            lambda number: get_line_barracks_status(number=number, lane=lane.value)\n",
    "        )\n",
    "        \n",
    "    # we don't need old barracks_status col anymore\n",
    "    del match_df[init_col]\n",
    "    \n",
    "# Let's add \"megacreeps\" columns for convenience\n",
    "match_df[f\"m_creeps_dire\"] = match_df.apply(lambda row: has_megacreeps(row=row, enemy_team=\"radiant\"), axis=1)\n",
    "match_df[f\"m_creeps_radiant\"] = match_df.apply(lambda row: has_megacreeps(row=row, enemy_team=\"dire\"), axis=1)  \n",
    "\n",
    "# match_df prepared and we can store it into our database\n",
    "conn = create_connection(\"./dota.db\")\n",
    "match_df.to_sql(\"match\", conn, if_exists=\"replace\", index=None)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e599427",
   "metadata": {},
   "source": [
    "CREATE TABLE \"match\" (  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"match_id\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"start_time\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"duration\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"tower_status_radiant\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"tower_status_dire\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"first_blood_time\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"game_mode\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"radiant_win\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"negative_votes\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"positive_votes\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"cluster\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"top_lane_status_dire\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"middle_lane_status_dire\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"bottom_lane_status_dire\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"top_lane_status_radiant\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"middle_lane_status_radiant\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"bottom_lane_status_radiant\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"m_creeps_dire\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"m_creeps_radiant\" INTEGER  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea84cff",
   "metadata": {},
   "source": [
    "##### players_df preparation.\n",
    "I want to examine the next indicators using the players_df and match_df:\n",
    "- top ten most popular heroes;\n",
    "- top ten heroes with the hightest winrate;\n",
    "- top ten heroes with the lowest winrate;\n",
    "- top ten killers (heroes);\n",
    "- top ten \"suicide bomber\" (heroes);\n",
    "- top ten \"gold diggers\" (heroes);\n",
    "\n",
    "Players dataset info:\n",
    "individual players are identified by account_id but there is an option to play anonymously and roughly one third of the account_id are not available. Anonymous users have the value of 0 for account_id. Contains totals for kills, deaths, denies, etc. Player action counts are available, and are indicated by variable names beginning with unit_order_. Counts for reasons for acquiring or losing gold, and gaining experience, have prefixes gold_, and xp_.\n",
    "\n",
    "During the preparation on players_df, I will:\n",
    "- replace \"player_slot\" (int) column with a \"radiant\" (int) column with 1/0 values;\n",
    "- replace None (Text) values in \"stuns\" column with 0.0, and convert column type to float;\n",
    "- delete unusing columns, such as unit_ liker columns, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61982549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_radiant(number: int) -> int:\n",
    "    if 0 <= number < 5:\n",
    "        radiant = 1\n",
    "    else:\n",
    "        radiant = 0\n",
    "    return radiant\n",
    "\n",
    "players_df[\"radiant\"] = players_df.player_slot.apply(is_radiant)\n",
    "\n",
    "players_df.loc[(players_df[\"stuns\"] == \"None\"), \"stuns\"] = \"0.0\"\n",
    "players_df[\"stuns\"] = players_df[\"stuns\"].astype(float)\n",
    "\n",
    "columns_to_delete = [\n",
    "    col for col in players_df.columns.values \n",
    "    if col.startswith((\"unit_\", \"gold_\", \"item_\", \"xp_\")) and col != \"gold_per_min\"\n",
    "]\n",
    "\n",
    "for col in columns_to_delete:\n",
    "    del players_df[col]\n",
    "\n",
    "# players_df prepared and we can store it into our database\n",
    "conn = create_connection(\"./dota.db\")\n",
    "players_df.to_sql(\"players\", conn, if_exists=\"replace\", index=None)\n",
    "\n",
    "# also, let's create hero_names table. Dataset for this table does not need any preparation\n",
    "hero_names_df.to_sql(\"heroes\", conn, if_exists=\"replace\", index=None)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3056ae",
   "metadata": {},
   "source": [
    "CREATE TABLE \"players\" (  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"match_id\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"account_id\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"hero_id\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"player_slot\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"gold\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"gold_per_min\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"kills\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"deaths\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"assists\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"denies\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"last_hits\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"stuns\" REAL,\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"hero_damage\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"hero_healing\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"tower_damage\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"level\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"leaver_status\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"radiant\" INTEGER  \n",
    ")  \n",
    "  \n",
    "CREATE TABLE \"heroes\" (  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"name\" TEXT,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"hero_id\" INTEGER,  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;\"localized_name\" TEXT  \n",
    ")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffbe6b7",
   "metadata": {},
   "source": [
    "### Stage 3. Metrics Calculation\n",
    "\n",
    "##### Part 1. Lanes analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d855c4",
   "metadata": {},
   "source": [
    "1. Let's see how often a team wins if they have megacreeps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34dde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_creeps_winrate_query = \"\"\"\n",
    "WITH results AS (\n",
    "    SELECT SUM(CASE radiant.result WHEN 1 THEN radiant.qty ELSE 0 END) AS radiant_wins\n",
    "         , SUM(CASE radiant.result WHEN 0 THEN radiant.qty ELSE 0 END) AS radiant_losts\n",
    "         , SUM(CASE dire.result WHEN 1 THEN dire.qty ELSE 0 END)       AS dire_wins\n",
    "         , SUM(CASE dire.result WHEN 0 THEN dire.qty ELSE 0 END)       AS dire_losts\n",
    "    FROM (SELECT radiant_win AS result\n",
    "               , count(*)    AS qty\n",
    "          FROM match\n",
    "          WHERE m_creeps_radiant = 1\n",
    "          GROUP BY radiant_win) AS radiant\n",
    "             JOIN\n",
    "         (SELECT CASE radiant_win WHEN 1 THEN 0 ELSE 1 END AS result\n",
    "               , count(*)                                  AS qty\n",
    "          FROM match\n",
    "          WHERE m_creeps_dire = 1\n",
    "          GROUP BY radiant_win) AS dire\n",
    "         ON radiant.result = dire.result)\n",
    "SELECT (radiant_wins * 100) / (radiant_wins + radiant_losts) AS radiant_wins_percent\n",
    "     , (dire_wins * 100) / (dire_wins + dire_losts)          AS dire_wins_percent\n",
    "FROM results\n",
    "\"\"\"\n",
    "\n",
    "conn = create_connection(\"./dota.db\")\n",
    "m_creeps_winrate = pd.read_sql_query(m_creeps_winrate_query, conn)\n",
    "print(m_creeps_winrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3b58b0",
   "metadata": {},
   "source": [
    "As we can see, a radiant team as well as a dire team wins with megacreeps in 99% cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83089a53",
   "metadata": {},
   "source": [
    "2. Nomination \"Have won middle - have won the game\".\n",
    "\n",
    "Middle lane is the shortest and the most important lane in Dota2.\n",
    "In this section we will calculate a percent of games where a winner have destroyed \n",
    "only the middle lane buildings and have won a game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430656ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_lane_winrate_query = \"\"\"\n",
    "SELECT SUM(res.win_qty) * 100 / SUM(res.total_qty) AS win_rate\n",
    "FROM (SELECT SUM(radiant_win) AS win_qty\n",
    "           , COUNT(*)         AS total_qty\n",
    "      FROM match\n",
    "      WHERE middle_lane_status_dire = 0\n",
    "        and bottom_lane_status_dire = 1\n",
    "        and top_lane_status_dire = 1\n",
    "      UNION ALL\n",
    "      SELECT SUM(CASE radiant_win WHEN 1 THEN 0 ELSE 1 END) AS win_qty\n",
    "           , COUNT(*)                                       AS total_qty\n",
    "      FROM match\n",
    "      WHERE middle_lane_status_radiant = 0\n",
    "        and bottom_lane_status_radiant = 1\n",
    "        and top_lane_status_radiant = 1) AS res;\n",
    "\"\"\"\n",
    "mid_lane_winrate = pd.read_sql_query(mid_lane_winrate_query, conn)\n",
    "print(mid_lane_winrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f5a33a",
   "metadata": {},
   "source": [
    "Wow! 61% of all the games ended throught the only one middle lane! Quite interesting, isn't it?\n",
    "Let's check other two lanes by the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea01006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top lane\n",
    "\n",
    "top_lane_winrate_query = mid_lane_winrate_query.replace(\n",
    "    \"middle_lane_status_dire = 0\", \"middle_lane_status_dire = 1\"\n",
    ").replace(\n",
    "    \"top_lane_status_dire = 1\", \"top_lane_status_dire = 0\"\n",
    ").replace(\n",
    "    \"middle_lane_status_radiant = 0\", \"middle_lane_status_radiant = 1\"\n",
    ").replace(\n",
    "    \"top_lane_status_radiant = 1\", \"top_lane_status_radiant = 0\"\n",
    ")\n",
    "print(top_lane_winrate_query)\n",
    "\n",
    "top_lane_winrate = pd.read_sql_query(top_lane_winrate_query, conn)\n",
    "\n",
    "print(top_lane_winrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd766d6",
   "metadata": {},
   "source": [
    "Only 19%. It is a big difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9635b5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bottom lane\n",
    "\n",
    "bottom_lane_winrate_query = top_lane_winrate_query.replace(\n",
    "    \"top_lane_status_dire = 0\", \"top_lane_status_dire = 1\"\n",
    ").replace(\n",
    "    \"bottom_lane_status_dire = 1\", \"bottom_lane_status_dire = 0\"\n",
    ").replace(\n",
    "    \"top_lane_status_radiant = 0\", \"top_lane_status_radiant = 1\"\n",
    ").replace(\n",
    "    \"bottom_lane_status_radiant = 1\", \"bottom_lane_status_radiant = 0\"\n",
    ")\n",
    "print(bottom_lane_winrate_query)\n",
    "\n",
    "bottom_lane_winrate = pd.read_sql_query(bottom_lane_winrate_query, conn)\n",
    "\n",
    "print(bottom_lane_winrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c841a64b",
   "metadata": {},
   "source": [
    "29%. A bit better, but it is still much less than middle lane result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c38a41",
   "metadata": {},
   "source": [
    "#### Part 2. Heroes analysis\n",
    "\n",
    "###### 1. Top ten most popular heroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779fc11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_popular_query = \"\"\"\n",
    "SELECT h.localized_name AS hero_name, COUNT(*) AS pick_qty\n",
    "FROM players AS p\n",
    "JOIN heroes AS h\n",
    "ON p.hero_id = h.hero_id\n",
    "GROUP BY h.localized_name\n",
    "ORDER BY pick_qty DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "most_popular = pd.read_sql_query(most_popular_query, conn)\n",
    "print(most_popular)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5a9907",
   "metadata": {},
   "source": [
    "###### 2. Top ten heroes with the hightest winrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9010a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_winrate_query = \"\"\"\n",
    "WITH winners AS (\n",
    "    SELECT p.hero_id AS hero_id\n",
    "         , COUNT(*)  AS wins_qty\n",
    "    FROM players AS p\n",
    "    LEFT JOIN match AS m\n",
    "    ON p.match_id = m.match_id\n",
    "    WHERE (p.radiant = 1 AND m.radiant_win = 1)\n",
    "       OR (p.radiant = 0 AND m.radiant_win = 0)\n",
    "    GROUP BY hero_id\n",
    ")\n",
    "SELECT picks.hero_name\n",
    "     , picks.qty                      AS picks_qty\n",
    "     , w.wins_qty                     AS wins_qty\n",
    "     , (w.wins_qty * 100) / picks.qty AS win_rate\n",
    "FROM winners AS w\n",
    "      JOIN\n",
    "     (SELECT h.localized_name AS hero_name\n",
    "           , h.hero_id        AS hero_id\n",
    "           , COUNT(*)         AS qty\n",
    "      FROM players AS p\n",
    "      JOIN heroes AS h\n",
    "      ON p.hero_id = h.hero_id\n",
    "      GROUP BY h.hero_id) AS picks\n",
    "     ON picks.hero_id = w.hero_id\n",
    "ORDER BY win_rate DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "top_winrate = pd.read_sql_query(top_winrate_query, conn)\n",
    "print(top_winrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e106e5",
   "metadata": {},
   "source": [
    "It's interesting, that there is the only one hero in this DataFrame \n",
    "who also was represented in the previous result (the most popular heroes): \n",
    "\n",
    "That hero is Slardar! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79335047",
   "metadata": {},
   "source": [
    "###### 3. Top ten heroes with the lowest winrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26785738",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_winrate_query = top_winrate_query.replace(\"DESC\", \"ASC\")\n",
    "lowest_winrate = pd.read_sql_query(lowest_winrate_query, conn)\n",
    "print(lowest_winrate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6144c7",
   "metadata": {},
   "source": [
    "We can see here a quite popular hero - Lina (8255 picks), \n",
    "but at the same time she is the 7th from the bottom by the winrate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d34be5",
   "metadata": {},
   "source": [
    "###### 4. Top ten killers (AVG kills quantity per match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b80646",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_killers_query = \"\"\"\n",
    "SELECT h.localized_name       AS hero_name\n",
    "     , ROUND(AVG(p.kills), 2) AS kills_per_match\n",
    "FROM players AS p\n",
    "         JOIN heroes AS h\n",
    "              ON p.hero_id = h.hero_id\n",
    "GROUP BY h.hero_id\n",
    "ORDER BY kills_per_match DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "top_killers = pd.read_sql_query(top_killers_query, conn)\n",
    "print(top_killers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff4eb5",
   "metadata": {},
   "source": [
    "###### 5. Top ten \"suicide bombers\" (AVG deaths quantity per match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b9b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_feeders_query = top_killers_query.replace(\"kills\", \"deaths\")\n",
    "top_feeders = pd.read_sql_query(top_feeders_query, conn)\n",
    "print(top_feeders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b82dfcb",
   "metadata": {},
   "source": [
    "###### 6. Top ten \"gold diggers\" (AVG gold_per_minute value per match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d679e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_gold_diggers_query = top_killers_query.replace(\"kills\", \"gold_per_min\")\n",
    "top_gold_diggers = pd.read_sql_query(top_gold_diggers_query, conn)\n",
    "print(top_gold_diggers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
